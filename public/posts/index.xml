<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Posts on ovdixon</title>
    <link>https://ovdixon.com/posts/</link>
    <description>ovdixon (Posts)</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Tue, 07 Apr 2020 14:12:24 +1000</lastBuildDate>
    
    <atom:link href="https://ovdixon.com/posts/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Machine learning for beach litter detection üèù</title>
      <link>https://ovdixon.com/posts/litter-detection/</link>
      <pubDate>Tue, 07 Apr 2020 14:12:24 +1000</pubDate>
      
      <guid>https://ovdixon.com/posts/litter-detection/</guid>
      <description>&lt;h4 id=&#34;background&#34;&gt;Background&lt;/h4&gt;
&lt;p&gt;Huge amounts of litter wash up along coastlines around the world. Not only is this problem an ugly eyesore, it poses a devastating environmental impact to wildlife, water quality and human health. Currently the most commonly used method for monitoring the litter that washes onto coastlines is boots on the ground visual counting, often involving large teams of peoples. However if we consider the sheer size and accessibility of coastal areas in Australia alone this is overwhelmingly inefficient.&lt;/p&gt;
&lt;p&gt;I sought to explore the feasibility of training a simple machine learning model for object detection of beach litter. A forewarning that this is one of my first ventures into the world of ML so it was very much a learning process for myself included.&lt;/p&gt;
&lt;figure&gt;
    &lt;img src=&#34;ideation.png&#34;
         alt=&#34;Simple wireframe sketch (left) served as a template for designing the storyboard (right)&#34;/&gt; &lt;figcaption&gt;
            &lt;p&gt;Simple wireframe sketch (left) served as a template for designing the storyboard (right)&lt;/p&gt;
        &lt;/figcaption&gt;
&lt;/figure&gt;

</description>
    </item>
    
    <item>
      <title>Mobile Passport Scanner üõÇ</title>
      <link>https://ovdixon.com/posts/passport-scanner/</link>
      <pubDate>Tue, 07 Apr 2020 14:12:24 +1000</pubDate>
      
      <guid>https://ovdixon.com/posts/passport-scanner/</guid>
      <description>&lt;h4 id=&#34;problem&#34;&gt;Problem&lt;/h4&gt;
&lt;p&gt;In the hospitality industry, hotels are often required to provide passport data of guests to immigration services. Passport data can be manually entered and forwarded on, however this is inefficient when dealing with a large number of guests.&lt;/p&gt;
&lt;h4 id=&#34;ideation&#34;&gt;Ideation&lt;/h4&gt;
&lt;p&gt;A mobile application that uses the phones camera to scan the Machine Readable Zone (MRZ) from passports. From this MRZ, the passport can be verified and necessary guest data recorded to be forwarded onto immigration.&lt;/p&gt;
&lt;figure&gt;
    &lt;img src=&#34;ideation.png&#34;
         alt=&#34;Simple wireframe sketch (left) served as a template for designing the storyboard (right)&#34;/&gt; &lt;figcaption&gt;
            &lt;p&gt;Simple wireframe sketch (left) served as a template for designing the storyboard (right)&lt;/p&gt;
        &lt;/figcaption&gt;
&lt;/figure&gt;

&lt;h4 id=&#34;implementation&#34;&gt;Implementation&lt;/h4&gt;
&lt;p&gt;The app was developed for iOS using Xcode. An image of the passport is captured using the system document scanner, VisionKit. The scanned image is then processed using the VNRecognizeTextRequest class, an image analysis request that finds and recognises the the machine readable zone (MRZ) at the bottom of the passport. The MRZ lines are then parsed using third-party &lt;a href=&#34;https://github.com/Mattijah/QKMRZParser&#34;&gt;QKMRZParser&lt;/a&gt; framework to extract the name, passport number, nationality, date of birth, sex, and passport expiration date.&lt;/p&gt;
&lt;figure&gt;
    &lt;img src=&#34;demo.gif&#34;
         alt=&#34;Demo of scanning a passport into the app (running on iPad Pro 11)&#34; width=&#34;90%&#34;/&gt; &lt;figcaption&gt;
            &lt;p&gt;Demo of scanning a passport into the app (running on iPad Pro 11)&lt;/p&gt;
        &lt;/figcaption&gt;
&lt;/figure&gt;

&lt;h4 id=&#34;challenges&#34;&gt;Challenges&lt;/h4&gt;
&lt;p&gt;This was my first iOS project so I had some difficulty with Xcode but overall enjoyed the experience of coding in Swift. Because the app  processes sensitive passport information, I had to consider data privacy and protection. All data processed is stored locally on device, however the app would benefit from adding password protection. The app should adhere to GDRP laws as there is a legal basis for providing passport data to immigration services.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Generative Art üñº</title>
      <link>https://ovdixon.com/posts/generative-art/</link>
      <pubDate>Sat, 09 Mar 2019 19:22:42 +1100</pubDate>
      
      <guid>https://ovdixon.com/posts/generative-art/</guid>
      <description>&lt;p&gt;Computational systems allow for the realization and expression of ideas that are impossible in other media, or in reality. In such a way, generative computer art is a medium of expression beyond the realm of conventional art, one in which difference can be created within indifference. As part of a university course I took in Design Programming I was required to submit a design inspired by an historical example of computer art.&lt;/p&gt;
&lt;h4 id=&#34;inspiration&#34;&gt;Inspiration&lt;/h4&gt;
&lt;p&gt;Georg Nees was a German academic who is considered one of the pioneers of computer art and generative graphics. He was interested in the relationship between order and disorder in picture composition. This is reflected in the untitled artwork below; Here Nees has introduced random variables into the computer program to produce the disordered lines. These lines are framed within the ordered circles to produce a striking contrast. This artwork served as the inspiration for my own exploration into the practice of generative computer art.&lt;/p&gt;
&lt;figure&gt;
    &lt;img src=&#34;untitled.png&#34;
         alt=&#34;Untitled artwork by Georg Nees&#34;/&gt; &lt;figcaption&gt;
            &lt;p&gt;Untitled artwork by Georg Nees&lt;/p&gt;
        &lt;/figcaption&gt;
&lt;/figure&gt;

&lt;h4 id=&#34;implementation&#34;&gt;Implementation&lt;/h4&gt;
&lt;p&gt;My design was created using &lt;a href=&#34;https://p5js.org&#34;&gt;p5.js&lt;/a&gt;. This is a client-side library for creating graphic and interactive experiences, based on the core principles of Processing. You can view view the code and live design &lt;a href=&#34;https://www.openprocessing.org/sketch/687721&#34;&gt;here&lt;/a&gt; (doesn&amp;rsquo;t work well in Safari).&lt;/p&gt;
&lt;figure&gt;
    &lt;img src=&#34;generations.png&#34;
         alt=&#34;Six random generations of my design&#34;/&gt; &lt;figcaption&gt;
            &lt;p&gt;Six random generations of my design&lt;/p&gt;
        &lt;/figcaption&gt;
&lt;/figure&gt;

&lt;p&gt;I sought to create a program which would produce ordered patterns from the intersection of two seemingly disordered sets of lines. The absence of any border around the pattern is designed to evoke a sense of curiosity towards the direction and origin of the lines. The experience of being drawn into the pattern before the program generates a new pattern, is a provocative source of thought for the viewer about whether machines can produce works of artistic value.&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>